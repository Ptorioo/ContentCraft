#!/usr/bin/env python3
"""
åˆ†æ ATI æ¨¡å‹æ•ˆæœ
"""
import pandas as pd
import numpy as np
from scipy.stats import spearmanr, pearsonr
import os

# è®€å–è³‡æ–™
base_dir = os.path.join(os.path.dirname(__file__), '..', 'çµæœ')
test_df = pd.read_csv(os.path.join(base_dir, 'ati_test_per_post.csv'))
train_df = pd.read_csv(os.path.join(base_dir, 'ati_train_per_post.csv'))
brand_df = pd.read_csv(os.path.join(base_dir, 'ati_test_brand_agg.csv'))

print('=' * 70)
print('ğŸ“Š ATI æ¨¡å‹æ•ˆæœè©•ä¼°å ±å‘Š')
print('=' * 70)

# 1. åŸºæœ¬çµ±è¨ˆ
print('\nã€1. è³‡æ–™åŸºæœ¬çµ±è¨ˆã€‘')
print(f'è¨“ç·´é›†æ¨£æœ¬æ•¸: {len(train_df):,}')
print(f'æ¸¬è©¦é›†æ¨£æœ¬æ•¸: {len(test_df):,}')
print(f'å“ç‰Œæ•¸: {len(brand_df)}')
print(f'\næ¸¬è©¦é›† y å€¼çµ±è¨ˆ:')
print(f'  ç¯„åœ: [{test_df["y"].min():.6f}, {test_df["y"].max():.6f}]')
print(f'  å¹³å‡: {test_df["y"].mean():.6f}')
print(f'  ä¸­ä½æ•¸: {test_df["y"].median():.6f}')
print(f'  æ¨™æº–å·®: {test_df["y"].std():.6f}')
print(f'\næ¸¬è©¦é›† ATI_final çµ±è¨ˆ:')
print(f'  ç¯„åœ: [{test_df["ATI_final"].min():.2f}, {test_df["ATI_final"].max():.2f}]')
print(f'  å¹³å‡: {test_df["ATI_final"].mean():.2f}')
print(f'  ä¸­ä½æ•¸: {test_df["ATI_final"].median():.2f}')
print(f'  æ¨™æº–å·®: {test_df["ATI_final"].std():.2f}')

# 2. ç›¸é—œæ€§åˆ†æ
print('\nã€2. ç›¸é—œæ€§åˆ†æï¼ˆæ¸¬è©¦é›†ï¼‰ã€‘')
print('-' * 70)
metrics = [
    ('text_DS', 'Text æ¨¡æ…‹ DS'),
    ('image_DS', 'Image æ¨¡æ…‹ DS'),
    ('meta_DS', 'Meta æ¨¡æ…‹ DS'),
    ('DS_final', 'æœ€çµ‚ DS'),
    ('ATI_final', 'æœ€çµ‚ ATI')
]

results = []
for metric, name in metrics:
    if metric in test_df.columns:
        # ç§»é™¤ç¼ºå¤±å€¼
        mask = test_df[metric].notna() & test_df['y'].notna()
        if mask.sum() > 10:
            r_spearman, p_spearman = spearmanr(test_df.loc[mask, metric], test_df.loc[mask, 'y'])
            r_pearson, p_pearson = pearsonr(test_df.loc[mask, metric], test_df.loc[mask, 'y'])
            
            sig = '***' if p_spearman < 0.001 else '**' if p_spearman < 0.01 else '*' if p_spearman < 0.05 else ''
            results.append({
                'metric': name,
                'spearman_r': r_spearman,
                'spearman_p': p_spearman,
                'pearson_r': r_pearson,
                'pearson_p': p_pearson,
                'sig': sig
            })
            
            print(f'{name:20s}: Spearman r={r_spearman:7.4f} (p={p_spearman:.4f}){sig:3s} | Pearson r={r_pearson:7.4f} (p={p_pearson:.4f})')

# 3. åˆ†ä½æ•¸åˆ†æ
print('\nã€3. åˆ†ä½æ•¸åˆ†æï¼ˆæ¸¬è©¦é›†ï¼‰- ATI_final èˆ‡ y çš„é—œä¿‚ã€‘')
print('-' * 70)
test_df_clean = test_df.dropna(subset=['ATI_final', 'y']).copy()
if len(test_df_clean) > 0:
    try:
        test_df_clean['decile'] = pd.qcut(test_df_clean['ATI_final'], 10, labels=False, duplicates='drop')
        decile_stats = test_df_clean.groupby('decile').agg({
            'y': ['count', 'mean', 'median', 'std'],
            'ATI_final': 'mean'
        }).round(4)
        decile_stats.columns = ['æ¨£æœ¬æ•¸', 'y_å¹³å‡', 'y_ä¸­ä½æ•¸', 'y_æ¨™æº–å·®', 'ATI_å¹³å‡']
        print(decile_stats.to_string())
        
        # æª¢æŸ¥å–®èª¿æ€§
        y_means = decile_stats['y_å¹³å‡'].values
        if len(y_means) >= 3:
            # è¨ˆç®—è¶¨å‹¢
            increasing = sum(y_means[i] < y_means[i+1] for i in range(len(y_means)-1))
            decreasing = sum(y_means[i] > y_means[i+1] for i in range(len(y_means)-1))
            print(f'\nè¶¨å‹¢åˆ†æ: {increasing} å€‹å€é–“éå¢, {decreasing} å€‹å€é–“éæ¸›')
    except Exception as e:
        print(f'åˆ†ä½æ•¸åˆ†æå¤±æ•—: {e}')

# 4. å“ç‰Œå±¤ç´šåˆ†æ
print('\nã€4. å“ç‰Œå±¤ç´šç›¸é—œæ€§ã€‘')
print('-' * 70)
if 'y_mean' in brand_df.columns and 'ATI_final_mean' in brand_df.columns:
    mask = brand_df['ATI_final_mean'].notna() & brand_df['y_mean'].notna()
    if mask.sum() > 3:
        r_brand, p_brand = spearmanr(brand_df.loc[mask, 'ATI_final_mean'], brand_df.loc[mask, 'y_mean'])
        r_brand_p, p_brand_p = pearsonr(brand_df.loc[mask, 'ATI_final_mean'], brand_df.loc[mask, 'y_mean'])
        sig = '***' if p_brand < 0.001 else '**' if p_brand < 0.01 else '*' if p_brand < 0.05 else ''
        print(f'å“ç‰Œå¹³å‡ ATI vs å“ç‰Œå¹³å‡ y:')
        print(f'  Spearman r={r_brand:.4f} (p={p_brand:.4f}){sig}')
        print(f'  Pearson r={r_brand_p:.4f} (p={p_brand_p:.4f})')
        
        print(f'\nå“ç‰Œå±¤ç´šçµ±è¨ˆ:')
        print(f'  å“ç‰Œæ•¸: {len(brand_df)}')
        print(f'  å“ç‰Œå¹³å‡ y ç¯„åœ: [{brand_df["y_mean"].min():.4f}, {brand_df["y_mean"].max():.4f}]')
        print(f'  å“ç‰Œå¹³å‡ ATI ç¯„åœ: [{brand_df["ATI_final_mean"].min():.2f}, {brand_df["ATI_final_mean"].max():.2f}]')

# 5. å„æ¨¡æ…‹åˆ†æ•¸åˆ†ä½ˆ
print('\nã€5. å„æ¨¡æ…‹åˆ†æ•¸åˆ†ä½ˆï¼ˆæ¸¬è©¦é›†ï¼‰ã€‘')
print('-' * 70)
for mod in ['text', 'image', 'meta']:
    ds_col = f'{mod}_DS'
    ati_col = f'{mod}_ATI'
    if ds_col in test_df.columns:
        print(f'\n{mod.upper()} æ¨¡æ…‹:')
        print(f'  DS:  å¹³å‡={test_df[ds_col].mean():.4f}, æ¨™æº–å·®={test_df[ds_col].std():.4f}, ç¯„åœ=[{test_df[ds_col].min():.4f}, {test_df[ds_col].max():.4f}]')
        print(f'  ATI: å¹³å‡={test_df[ati_col].mean():.2f}, æ¨™æº–å·®={test_df[ati_col].std():.2f}, ç¯„åœ=[{test_df[ati_col].min():.2f}, {test_df[ati_col].max():.2f}]')

# 6. æ¥µå€¼æ¡ˆä¾‹
print('\nã€6. æ¥µå€¼æ¡ˆä¾‹ï¼ˆæ¸¬è©¦é›†ï¼‰ã€‘')
print('-' * 70)
print('æœ€é«˜ y å€¼çš„å‰ 5 ç¯‡è²¼æ–‡ï¼ˆé«˜äº’å‹•ç‡ï¼‰:')
top_y = test_df.nlargest(5, 'y')[['brand', 'y', 'ATI_final', 'DS_final', 'count_like', 'count_comment', 'followers']]
for idx, row in top_y.iterrows():
    print(f"  {row['brand']:25s} | y={row['y']:8.4f} | ATI={row['ATI_final']:6.2f} | æŒ‰è®š={row['count_like']:5.0f} | ç•™è¨€={row['count_comment']:3.0f} | è¿½è¹¤è€…={row['followers']:8.0f}")

print('\næœ€ä½ ATIï¼ˆæœ€æ–°ç©ï¼‰çš„å‰ 5 ç¯‡è²¼æ–‡:')
low_ati = test_df.nsmallest(5, 'ATI_final')[['brand', 'y', 'ATI_final', 'DS_final', 'count_like', 'count_comment']]
for idx, row in low_ati.iterrows():
    print(f"  {row['brand']:25s} | y={row['y']:8.4f} | ATI={row['ATI_final']:6.2f} | DS={row['DS_final']:.4f} | æŒ‰è®š={row['count_like']:5.0f}")

print('\næœ€é«˜ ATIï¼ˆæœ€ä¸æ–°ç©ï¼‰çš„å‰ 5 ç¯‡è²¼æ–‡:')
high_ati = test_df.nlargest(5, 'ATI_final')[['brand', 'y', 'ATI_final', 'DS_final', 'count_like', 'count_comment']]
for idx, row in high_ati.iterrows():
    print(f"  {row['brand']:25s} | y={row['y']:8.4f} | ATI={row['ATI_final']:6.2f} | DS={row['DS_final']:.4f} | æŒ‰è®š={row['count_like']:5.0f}")

# 7. è¨“ç·´é›† vs æ¸¬è©¦é›†æ¯”è¼ƒ
print('\nã€7. è¨“ç·´é›† vs æ¸¬è©¦é›†æ¯”è¼ƒã€‘')
print('-' * 70)
if 'y' in train_df.columns and 'ATI_final' in train_df.columns:
    train_mask = train_df['ATI_final'].notna() & train_df['y'].notna()
    test_mask = test_df['ATI_final'].notna() & test_df['y'].notna()
    
    if train_mask.sum() > 10 and test_mask.sum() > 10:
        r_train, p_train = spearmanr(train_df.loc[train_mask, 'ATI_final'], train_df.loc[train_mask, 'y'])
        r_test, p_test = spearmanr(test_df.loc[test_mask, 'ATI_final'], test_df.loc[test_mask, 'y'])
        
        print(f'è¨“ç·´é›†: Spearman r={r_train:.4f} (p={p_train:.4f})')
        print(f'æ¸¬è©¦é›†: Spearman r={r_test:.4f} (p={p_test:.4f})')
        print(f'å·®ç•°: {abs(r_test - r_train):.4f}')

# 8. ç¸½çµè©•ä¼°
print('\n' + '=' * 70)
print('ã€ç¸½çµè©•ä¼°ã€‘')
print('=' * 70)

# æ‰¾å‡ºæœ€ä½³ç›¸é—œæ€§
if results:
    best = max(results, key=lambda x: abs(x['spearman_r']))
    print(f'âœ… æœ€ä½³ç›¸é—œæ€§: {best["metric"]} (Spearman r={best["spearman_r"]:.4f})')
    
    # è©•ä¼°æ•ˆæœ
    final_ati_result = next((r for r in results if 'æœ€çµ‚ ATI' in r['metric']), None)
    if final_ati_result:
        r_final = abs(final_ati_result['spearman_r'])
        p_final = final_ati_result['spearman_p']
        
        if r_final < 0.1:
            assessment = "âŒ æ•ˆæœä¸ä½³ï¼šç›¸é—œæ€§æ¥µå¼±"
        elif r_final < 0.3:
            assessment = "âš ï¸  æ•ˆæœæœ‰é™ï¼šç›¸é—œæ€§å¼±"
        elif r_final < 0.5:
            assessment = "âš ï¸  æ•ˆæœä¸­ç­‰ï¼šç›¸é—œæ€§ä¸­ç­‰"
        elif r_final < 0.7:
            assessment = "âœ… æ•ˆæœè‰¯å¥½ï¼šç›¸é—œæ€§è¼ƒå¼·"
        else:
            assessment = "âœ… æ•ˆæœå„ªç§€ï¼šç›¸é—œæ€§å¼·"
        
        print(f'\nğŸ“ˆ æœ€çµ‚ ATI æ¨¡å‹è©•ä¼°:')
        print(f'   ç›¸é—œæ€§å¼·åº¦: {r_final:.4f} (p={p_final:.4f})')
        print(f'   è©•ä¼°çµæœ: {assessment}')
        
        if p_final >= 0.05:
            print(f'   âš ï¸  æ³¨æ„ï¼šp å€¼ >= 0.05ï¼Œçµ±è¨ˆä¸Šä¸é¡¯è‘—')
        else:
            print(f'   âœ“ çµ±è¨ˆé¡¯è‘—æ€§ï¼šp < 0.05')

print('\n' + '=' * 70)

