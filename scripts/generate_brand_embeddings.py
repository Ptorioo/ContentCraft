"""
ç”Ÿæˆå“ç‰Œç´šåˆ¥çš„åŸå§‹ CLIP embeddingï¼Œç”¨æ–¼è¨ˆç®—å“ç‰Œç›¸ä¼¼åº¦

é€™å€‹è…³æœ¬æœƒï¼š
1. è®€å– modal_embeddings_v2.npz ä¸­çš„ embedding
2. ç‚ºæ¯å€‹å“ç‰Œè¨ˆç®—å¹³å‡ embeddingï¼ˆçµåˆ caption + OCR + imageï¼‰
3. ä¿å­˜ç‚º JSON ä¾›å¾Œç«¯ä½¿ç”¨
"""

import numpy as np
import pandas as pd
import json
from pathlib import Path

# è¨­å®šè·¯å¾‘
ROOT = Path(__file__).parent.parent
EMBEDDING_FILE = ROOT / 'çµæœ' / 'modal_embeddings_v2.npz'
TEST_CSV = ROOT / 'çµæœ' / 'ati_test_per_post.csv'
TRAIN_CSV = ROOT / 'çµæœ' / 'ati_train_per_post.csv'
OUTPUT_FILE = ROOT / 'src' / 'data' / 'generated' / 'brand_embeddings.json'

# ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)

print("ğŸ“Š é–‹å§‹ç”Ÿæˆå“ç‰Œç´š embedding...")

# 1. è®€å– embedding
print("\n1ï¸âƒ£ è®€å– embedding æª”æ¡ˆ...")
data = np.load(EMBEDDING_FILE, allow_pickle=True)
cap_test = data['cap_test']  # (590, 512)
ocr_test = data['ocr_test']  # (590, 512)
img_test = data['img_test']  # (590, 512)

# è®€å–è¨“ç·´é›† embedding
cap_train = data.get('cap_train', None)
ocr_train = data.get('ocr_train', None)
img_train = data.get('img_train', None)

print(f"   âœ“ æ¸¬è©¦é›†: {cap_test.shape[0]} å€‹è²¼æ–‡")
if cap_train is not None:
    print(f"   âœ“ è¨“ç·´é›†: {cap_train.shape[0]} å€‹è²¼æ–‡")

# 2. è®€å–å“ç‰Œè³‡æ–™
print("\n2ï¸âƒ£ è®€å–å“ç‰Œè³‡æ–™...")
df_test = pd.read_csv(TEST_CSV)
print(f"   âœ“ æ¸¬è©¦é›†: {len(df_test)} ç¯‡è²¼æ–‡ï¼Œ{df_test['brand'].nunique()} å€‹å“ç‰Œ")

df_train = None
if TRAIN_CSV.exists():
    df_train = pd.read_csv(TRAIN_CSV)
    print(f"   âœ“ è¨“ç·´é›†: {len(df_train)} ç¯‡è²¼æ–‡ï¼Œ{df_train['brand'].nunique()} å€‹å“ç‰Œ")
    df_all = pd.concat([df_test, df_train], ignore_index=True)
    print(f"   âœ“ åˆä½µå¾Œ: {len(df_all)} ç¯‡è²¼æ–‡ï¼Œ{df_all['brand'].nunique()} å€‹å“ç‰Œ")
else:
    df_all = df_test

# 3. çµ„åˆ embeddingï¼ˆcaption + OCR + image = 1536 ç¶­ï¼‰
print("\n3ï¸âƒ£ çµ„åˆ embedding...")
text_emb_test = np.hstack([cap_test, ocr_test])  # (590, 1024)
full_emb_test = np.hstack([text_emb_test, img_test])  # (590, 1536)

if cap_train is not None and ocr_train is not None and img_train is not None:
    text_emb_train = np.hstack([cap_train, ocr_train])
    full_emb_train = np.hstack([text_emb_train, img_train])
    full_emb = np.vstack([full_emb_test, full_emb_train])  # (total, 1536)
    print(f"   âœ“ åˆä½µ embedding: {full_emb.shape}")
else:
    full_emb = full_emb_test
    print(f"   âš ï¸  åƒ…ä½¿ç”¨æ¸¬è©¦é›† embedding: {full_emb.shape}")

# 4. è¨ˆç®—æ¯å€‹å“ç‰Œçš„å¹³å‡ embedding
print("\n4ï¸âƒ£ è¨ˆç®—å“ç‰Œç´š embedding...")
brands = df_all['brand'].unique()
brand_embeddings = {}

for brand in brands:
    # æ‰¾å‡ºè©²å“ç‰Œåœ¨æ¸¬è©¦é›†å’Œè¨“ç·´é›†ä¸­çš„ç´¢å¼•
    brand_mask_test = df_test['brand'] == brand
    brand_indices_test = np.where(brand_mask_test)[0]
    
    brand_indices_train = []
    if df_train is not None:
        brand_mask_train = df_train['brand'] == brand
        brand_indices_train = np.where(brand_mask_train)[0] + len(df_test)
    
    all_indices = list(brand_indices_test) + list(brand_indices_train)
    
    if len(all_indices) == 0:
        continue
    
    # è¨ˆç®—è©²å“ç‰Œæ‰€æœ‰è²¼æ–‡çš„å¹³å‡ embedding
    brand_emb = full_emb[all_indices].mean(axis=0)  # (1536,)
    
    # L2 æ­£è¦åŒ–ï¼ˆç”¨æ–¼ cosine similarityï¼‰
    norm = np.linalg.norm(brand_emb)
    if norm > 0:
        brand_emb = brand_emb / norm
    
    brand_embeddings[brand] = brand_emb.tolist()

print(f"   âœ“ è¨ˆç®—å®Œæˆï¼Œå…± {len(brand_embeddings)} å€‹å“ç‰Œ")
print(f"   âœ“ Embedding ç¶­åº¦: 1536 (caption 512 + OCR 512 + image 512)")

# 5. ä¿å­˜ç‚º JSON
print(f"\n5ï¸âƒ£ ä¿å­˜åˆ° {OUTPUT_FILE}...")
output_data = {
    'embedding_dim': 1536,
    'n_brands': len(brand_embeddings),
    'embeddings': brand_embeddings,
}

with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
    json.dump(output_data, f, ensure_ascii=False, indent=2)

print(f"   âœ“ æª”æ¡ˆå·²å„²å­˜")
print(f"\nâœ… å®Œæˆï¼å…±è™•ç† {len(brand_embeddings)} å€‹å“ç‰Œ")

